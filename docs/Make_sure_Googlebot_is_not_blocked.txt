Make sure Googlebot is not blockedBlocking Googlebot from accessing a site can directly affect Googlebot’s ability to crawl and index the site’s content, and may lead to a loss of ranking in Google’s search results. Unfortunately, many webmasters accidentally block Googlebot from accessing their site and, because Googlebot needs to be able to access a site in order to retrieve and honor the directions in its robots.txt file, may not even know it.
When Google detects this issue, we may notify you that Googlebot is being blocked.
You can see all pages blocked on your site in the Index Coverage report, or test a specific page using the URL Inspection tool.
Was this helpful?How can we improve it?YesNoSubmit
true
Crawling and indexingOverview of crawling and indexing topicsManage your sitemapsBlock access to your contentRemove information from GoogleTell Google about your duplicate contentAsk Google to recrawl your URLsMake sure Googlebot is not blockedCreate custom 404 pagesTransfer, move, or migrate your siteInternational and multilingual sitesSpecial tags that Google understandsGoogle crawlersCrawl Stats reportChange Googlebot crawl rate
New to Search Console? Never used Search Console before? Start here, whether you're a complete beginner, an SEO expert, or a website developer.